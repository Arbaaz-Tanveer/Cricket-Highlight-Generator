{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b5f05c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Scanning video for replay events...\n",
      "‚úÖ Detected WICKET at 18.00s (corr=0.62)\n",
      "‚úÖ Detected WICKET at 334.00s (corr=0.61)\n",
      "‚úÖ Detected FOUR at 510.00s (corr=0.59)\n",
      "‚úÖ Detected WICKET at 568.00s (corr=0.73)\n",
      "‚úÖ Detected WICKET at 652.00s (corr=0.75)\n",
      "‚úÖ Detected WICKET at 767.00s (corr=0.62)\n",
      "‚úÖ Detected FOUR at 852.00s (corr=0.51)\n",
      "‚úÖ Detected FOUR at 883.00s (corr=0.54)\n",
      "‚úÖ Detected WICKET at 932.00s (corr=0.70)\n",
      "‚úÖ Detected WICKET at 1071.00s (corr=0.57)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÇÔ∏è Extracting clips...\n",
      "Moviepy - Building video clips\\wicket_1.mp4.\n",
      "Moviepy - Writing video clips\\wicket_1.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 5559/12128 [05:56<00:11, 588.48it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Failed to cut clip at 18.00s: must be real number, not NoneType\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 5559/12128 [05:56<00:11, 588.48it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video clips\\wicket_2.mp4.\n",
      "Moviepy - Writing video clips\\wicket_2.mp4\n",
      "\n",
      "‚ùå Failed to cut clip at 334.00s: must be real number, not NoneType\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 5559/12128 [05:56<00:11, 588.48it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video clips\\four_3.mp4.\n",
      "Moviepy - Writing video clips\\four_3.mp4\n",
      "\n",
      "‚ùå Failed to cut clip at 510.00s: must be real number, not NoneType\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 5559/12128 [05:57<00:11, 588.48it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video clips\\wicket_4.mp4.\n",
      "Moviepy - Writing video clips\\wicket_4.mp4\n",
      "\n",
      "‚ùå Failed to cut clip at 568.00s: must be real number, not NoneType\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 5559/12128 [05:57<00:11, 588.48it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video clips\\wicket_5.mp4.\n",
      "Moviepy - Writing video clips\\wicket_5.mp4\n",
      "\n",
      "‚ùå Failed to cut clip at 652.00s: must be real number, not NoneType\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 5559/12128 [05:57<00:11, 588.48it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video clips\\wicket_6.mp4.\n",
      "Moviepy - Writing video clips\\wicket_6.mp4\n",
      "\n",
      "‚ùå Failed to cut clip at 767.00s: must be real number, not NoneType\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 5559/12128 [05:58<00:11, 588.48it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video clips\\four_7.mp4.\n",
      "Moviepy - Writing video clips\\four_7.mp4\n",
      "\n",
      "‚ùå Failed to cut clip at 852.00s: must be real number, not NoneType\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 5559/12128 [05:58<00:11, 588.48it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video clips\\four_8.mp4.\n",
      "Moviepy - Writing video clips\\four_8.mp4\n",
      "\n",
      "‚ùå Failed to cut clip at 883.00s: must be real number, not NoneType\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 5559/12128 [05:58<00:11, 588.48it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video clips\\wicket_9.mp4.\n",
      "Moviepy - Writing video clips\\wicket_9.mp4\n",
      "\n",
      "‚ùå Failed to cut clip at 932.00s: must be real number, not NoneType\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 5559/12128 [05:59<00:11, 588.48it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video clips\\wicket_10.mp4.\n",
      "Moviepy - Writing video clips\\wicket_10.mp4\n",
      "\n",
      "‚ùå Failed to cut clip at 1071.00s: must be real number, not NoneType\n",
      "‚ö†Ô∏è No valid replay clips were extracted.\n"
     ]
    }
   ],
   "source": [
    "# Step 0: Install Dependencies (run once if needed)\n",
    "# %pip install opencv-python moviepy numpy\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from moviepy.editor import VideoFileClip, concatenate_videoclips\n",
    "\n",
    "# Step 1: Configuration Parameters\n",
    "video_path = r\"D:\\Ayush\\PROJECTS\\EE655\\Matches\\matchclip.mp4\"  # Main video\n",
    "output_dir = \"clips\"\n",
    "highlight_output = \"highlights.mp4\"\n",
    "\n",
    "clip_duration = 8  # Seconds per replay clip\n",
    "pre_buffer = 2     # Seconds before replay shown\n",
    "threshold = 0.5    # Correlation threshold\n",
    "\n",
    "# Step 2: Load Replay Templates\n",
    "template_paths = {\n",
    "    \"wicket\": r\"D:\\Ayush\\PROJECTS\\EE655\\templates\\replay_wicket.png\",\n",
    "    \"four\": r\"D:\\Ayush\\PROJECTS\\EE655\\templates\\replay_four.png\",\n",
    "    \"six\": r\"D:\\Ayush\\PROJECTS\\EE655\\templates\\replay_six.png\",\n",
    "}\n",
    "\n",
    "templates = {}\n",
    "template_means = {}\n",
    "for label, path in template_paths.items():\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (img.shape[1] // 2, img.shape[0] // 2))  # Resize to half\n",
    "    templates[label] = img.astype(np.float32)\n",
    "    template_means[label] = np.mean(templates[label])\n",
    "\n",
    "# Step 3: Create Output Folder\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Step 4: Define Correlation Function\n",
    "def compute_correlation(frame_gray, template, template_mean):\n",
    "    frame = cv2.resize(frame_gray, (template.shape[1], template.shape[0]))\n",
    "    frame = frame.astype(np.float32)\n",
    "    frame_mean = np.mean(frame)\n",
    "\n",
    "    numerator = np.sum((frame - frame_mean) * (template - template_mean))\n",
    "    denominator = np.sqrt(np.sum((frame - frame_mean) ** 2) * np.sum((template - template_mean) ** 2))\n",
    "    if denominator == 0:\n",
    "        return 0\n",
    "    return numerator / denominator\n",
    "\n",
    "# Step 5: Scan Video for Replay Frames\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_interval = int(fps * 0.5)  # Check every 0.5 seconds\n",
    "\n",
    "frame_num = 0\n",
    "timestamps = []  # List of tuples: (timestamp, label)\n",
    "\n",
    "print(\"üîç Scanning video for replay events...\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    if frame_num % frame_interval == 0:\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        for label, template in templates.items():\n",
    "            corr = compute_correlation(gray, template, template_means[label])\n",
    "            if corr > threshold:\n",
    "                timestamp = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0\n",
    "                if not timestamps or abs(timestamp - timestamps[-1][0]) > clip_duration:\n",
    "                    timestamps.append((timestamp, label))\n",
    "                    print(f\"‚úÖ Detected {label.upper()} at {timestamp:.2f}s (corr={corr:.2f})\")\n",
    "                break  # Avoid multiple detections for same frame\n",
    "\n",
    "    frame_num += 1\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Step 6: Extract Replay Clips\n",
    "clips = []\n",
    "video = VideoFileClip(video_path)\n",
    "\n",
    "print(\"\\n‚úÇÔ∏è Extracting clips...\")\n",
    "\n",
    "for i, (ts, label) in enumerate(timestamps):\n",
    "    start = max(0, ts - pre_buffer)\n",
    "    end = start + clip_duration\n",
    "\n",
    "    try:\n",
    "        subclip = video.subclip(start, end).without_audio()\n",
    "        if subclip.duration == 0:\n",
    "            print(f\"‚ö†Ô∏è Skipping {label}_{i+1} - zero duration\")\n",
    "            continue\n",
    "\n",
    "        clip_path = os.path.join(output_dir, f\"{label}_{i+1}.mp4\")\n",
    "        subclip.write_videofile(\n",
    "            clip_path,\n",
    "            codec=\"libx264\",\n",
    "            audio=False,\n",
    "            verbose=False,\n",
    "            logger=None\n",
    "        )\n",
    "        clips.append(VideoFileClip(clip_path))\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to cut clip at {ts:.2f}s: {e}\")\n",
    "\n",
    "video.close()\n",
    "\n",
    "# Step 7: Merge All Clips into Final Highlights\n",
    "if clips:\n",
    "    print(\"\\nüé¨ Generating final highlights...\")\n",
    "    final = concatenate_videoclips(clips)\n",
    "    final.write_videofile(highlight_output, codec=\"libx264\", audio=False)\n",
    "    print(f\"‚úÖ Highlights saved to: {highlight_output}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No valid replay clips were extracted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec9fa070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Scanning for replay events...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Detected FOUR at 18.0s (corr=0.67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Detected FOUR at 510.0s (corr=0.59)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning frames:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 14100/30000 [01:47<02:01, 131.06it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 83\u001b[39m\n\u001b[32m     81\u001b[39m best_label, best_corr = \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[32m0\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m label, tpl \u001b[38;5;129;01min\u001b[39;00m templates.items():\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     c = \u001b[43mcorr_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtpl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m c > best_corr:\n\u001b[32m     85\u001b[39m         best_corr, best_label = c, label\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 54\u001b[39m, in \u001b[36mcorr_match\u001b[39m\u001b[34m(frame_gray, tpl)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcorr_match\u001b[39m(frame_gray, tpl):\n\u001b[32m     53\u001b[39m     \u001b[38;5;66;03m# Resize frame to template size\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     f = \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_gray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m.astype(np.float32)\n\u001b[32m     55\u001b[39m     t = tpl\n\u001b[32m     56\u001b[39m     num = np.sum((f - f.mean()) * (t - t.mean()))\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# üëâ Complete Highlight Generator without OCR (Template Matching Only)\n",
    "# Installs (run once):\n",
    "# pip install opencv-python numpy moviepy tqdm\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from moviepy.editor import VideoFileClip, concatenate_videoclips\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Configuration ---\n",
    "video_path = r\"D:\\Ayush\\PROJECTS\\EE655\\Matches\\matchclip.mp4\"\n",
    "output_dir = \"clips\"\n",
    "frame_dir = \"detected_frames\"\n",
    "highlight_output = \"highlight_video.mp4\"\n",
    "\n",
    "# Template images for replay detection\n",
    "template_paths = {\n",
    "    'wicket': r\"D:\\Ayush\\PROJECTS\\EE655\\templates\\replay_wicket.png\",\n",
    "    'four':   r\"D:\\Ayush\\PROJECTS\\EE655\\templates\\replay_four.png\",\n",
    "    'six':    r\"D:\\Ayush\\PROJECTS\\EE655\\templates\\replay_six.png\"\n",
    "}\n",
    "# Trophy screen template to ignore\n",
    "trophy_path = r\"D:\\Ayush\\PROJECTS\\EE655\\templates\\trophy.png\"\n",
    "\n",
    "# Detection parameters\n",
    "threshold = 0.5           # Correlation threshold for replay templates\n",
    "trophy_threshold = 0.7    # Correlation threshold for trophy (skip if above)\n",
    "clip_margin = 5           # Seconds before & after event to include\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(frame_dir, exist_ok=True)\n",
    "\n",
    "# --- Load Templates ---\n",
    "templates = {}\n",
    "for label, path in template_paths.items():\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"Template not found: {path}\")\n",
    "    # Resize to half for speed\n",
    "    img = cv2.resize(img, (img.shape[1]//2, img.shape[0]//2))\n",
    "    templates[label] = img.astype(np.float32)\n",
    "\n",
    "trophy_img = cv2.imread(trophy_path, cv2.IMREAD_GRAYSCALE)\n",
    "if trophy_img is None:\n",
    "    raise FileNotFoundError(f\"Trophy template not found: {trophy_path}\")\n",
    "# Resize similarly\n",
    "h, w = templates[next(iter(templates))].shape\n",
    "# Crop or resize trophy to match frame sample size\n",
    "# Here assume trophy full frame: no resize for trophy\n",
    "\n",
    "def corr_match(frame_gray, tpl):\n",
    "    # Resize frame to template size\n",
    "    f = cv2.resize(frame_gray, (tpl.shape[1], tpl.shape[0])).astype(np.float32)\n",
    "    t = tpl\n",
    "    num = np.sum((f - f.mean()) * (t - t.mean()))\n",
    "    den = np.sqrt(np.sum((f - f.mean())**2) * np.sum((t - t.mean())**2))\n",
    "    return num/den if den!=0 else 0\n",
    "\n",
    "# --- Scan Video ---\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "duration = frame_count / fps\n",
    "\n",
    "timestamps = []  # (start, end, label)\n",
    "last_ts = -clip_margin\n",
    "frame_idx = 0\n",
    "\n",
    "print(\"üîç Scanning for replay events...\")\n",
    "for _ in tqdm(range(frame_count), desc=\"Scanning frames\"):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    if frame_idx % int(fps) == 0:\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        # Skip trophy screens\n",
    "        if corr_match(gray, trophy_img) >= trophy_threshold:\n",
    "            frame_idx += 1; continue\n",
    "        # Check each replay type\n",
    "        best_label, best_corr = None, 0\n",
    "        for label, tpl in templates.items():\n",
    "            c = corr_match(gray, tpl)\n",
    "            if c > best_corr:\n",
    "                best_corr, best_label = c, label\n",
    "        if best_corr >= threshold:\n",
    "            ts = frame_idx / fps\n",
    "            if ts - last_ts > clip_margin:\n",
    "                # Save detected frame\n",
    "                cv2.imwrite(os.path.join(frame_dir, f\"{best_label}_{int(ts)}.jpg\"), frame)\n",
    "                print(f\"‚úÖ Detected {best_label.upper()} at {ts:.1f}s (corr={best_corr:.2f})\")\n",
    "                timestamps.append((max(0, ts-clip_margin), min(duration, ts+clip_margin), best_label))\n",
    "                last_ts = ts\n",
    "    frame_idx += 1\n",
    "cap.release()\n",
    "\n",
    "# --- Extract Clips ---\n",
    "print(\"\\n‚úÇÔ∏è Extracting clips...\")\n",
    "clips = []\n",
    "for idx, (start, end, label) in enumerate(timestamps, 1):\n",
    "    try:\n",
    "        clip = VideoFileClip(video_path).subclip(start, end).without_audio()\n",
    "        clip_path = os.path.join(output_dir, f\"{label}_{idx}.mp4\")\n",
    "        print(f\"Saving clip {idx}: {label} [{start:.1f}-{end:.1f}s]\")\n",
    "        clip.write_videofile(clip_path, codec=\"libx264\", audio=False, verbose=False, logger=None)\n",
    "        clips.append(clip)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error extracting clip {idx}: {e}\")\n",
    "\n",
    "# --- Merge Clips ---\n",
    "if clips:\n",
    "    print(\"\\nüé¨ Merging clips into highlights...\")\n",
    "    final = concatenate_videoclips(clips)\n",
    "    final.write_videofile(highlight_output, codec=\"libx264\", audio=False)\n",
    "    print(f\"‚úÖ Highlights saved as {highlight_output}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No clips extracted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5827b22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Scanning video for replays...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Detected FOUR at 652.56s ‚Üí saved detections/four_652.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Detected FOUR at 652.76s ‚Üí saved detections/four_652.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Detected FOUR at 652.96s ‚Üí saved detections/four_652.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Detected FOUR at 653.16s ‚Üí saved detections/four_653.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Detected FOUR at 653.36s ‚Üí saved detections/four_653.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Detected FOUR at 653.56s ‚Üí saved detections/four_653.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Detected FOUR at 653.76s ‚Üí saved detections/four_653.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Detected FOUR at 653.96s ‚Üí saved detections/four_653.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Detected FOUR at 654.16s ‚Üí saved detections/four_654.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Detected FOUR at 654.36s ‚Üí saved detections/four_654.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Detected FOUR at 654.56s ‚Üí saved detections/four_654.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Detected FOUR at 654.76s ‚Üí saved detections/four_654.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Detected FOUR at 654.96s ‚Üí saved detections/four_654.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Detected FOUR at 655.16s ‚Üí saved detections/four_655.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Detected FOUR at 655.36s ‚Üí saved detections/four_655.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Detected FOUR at 655.56s ‚Üí saved detections/four_655.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Detected WICKET at 943.56s ‚Üí saved detections/wicket_943.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 5309/6000 [39:21<05:07,  2.25it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 56\u001b[39m\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m event_type, template \u001b[38;5;129;01min\u001b[39;00m templates.items():\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mmatch_template\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_gray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorrelation_threshold\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     57\u001b[39m         replay_timestamps.append((timestamp, event_type))\n\u001b[32m     58\u001b[39m         frame_filename = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mframe_save_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(timestamp)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.jpg\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mmatch_template\u001b[39m\u001b[34m(frame_gray, template, threshold)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmatch_template\u001b[39m(frame_gray, template, threshold):\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     res = \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatchTemplate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_gray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTM_CCOEFF_NORMED\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.max(res) > threshold\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from moviepy.editor import VideoFileClip, concatenate_videoclips\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "video_path = r\"D:\\Ayush\\PROJECTS\\EE655\\Matches\\matchclip.mp4\"\n",
    "output_dir = 'clips'\n",
    "frame_save_dir = 'detections'\n",
    "templates = {\n",
    "    'wicket': cv2.imread(r'D:\\Ayush\\PROJECTS\\EE655\\templates\\replay_wicket.png', 0),\n",
    "    'four': cv2.imread(r'D:\\Ayush\\PROJECTS\\EE655\\templates\\replay_four.png', 0),\n",
    "    'six': cv2.imread(r'D:\\Ayush\\PROJECTS\\EE655\\templates\\replay_six.png', 0)\n",
    "}\n",
    "trophy_template = cv2.imread(r'D:\\Ayush\\PROJECTS\\EE655\\templates\\trophy.png', 0)\n",
    "correlation_threshold = 0.7\n",
    "trophy_threshold = 0.8\n",
    "clip_duration = 10\n",
    "frame_gap_seconds = 0.2  # Check every 0.2s\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(frame_save_dir, exist_ok=True)\n",
    "\n",
    "# --- DETECTION ---\n",
    "def match_template(frame_gray, template, threshold):\n",
    "    res = cv2.matchTemplate(frame_gray, template, cv2.TM_CCOEFF_NORMED)\n",
    "    return np.max(res) > threshold\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    raise ValueError(\"‚ùå Could not open the video. Check the path.\")\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "if fps == 0:\n",
    "    print(\"‚ö†Ô∏è FPS is 0, defaulting to 25.\")\n",
    "    fps = 25\n",
    "\n",
    "frame_gap = int(fps * frame_gap_seconds)\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "replay_timestamps = []\n",
    "\n",
    "print(\"üîç Scanning video for replays...\")\n",
    "for i in tqdm(range(0, frame_count, frame_gap)):\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "    timestamp = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    if match_template(frame_gray, trophy_template, trophy_threshold):\n",
    "        continue\n",
    "\n",
    "    for event_type, template in templates.items():\n",
    "        if match_template(frame_gray, template, correlation_threshold):\n",
    "            replay_timestamps.append((timestamp, event_type))\n",
    "            frame_filename = f\"{frame_save_dir}/{event_type}_{int(timestamp)}.jpg\"\n",
    "            cv2.imwrite(frame_filename, frame)\n",
    "            print(f\"‚úÖ Detected {event_type.upper()} at {timestamp:.2f}s ‚Üí saved {frame_filename}\")\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# --- CLIP EXTRACTION ---\n",
    "clips = []\n",
    "video = VideoFileClip(video_path)\n",
    "print(\"‚úÇÔ∏è Extracting clips...\")\n",
    "\n",
    "for idx, (timestamp, event_type) in enumerate(replay_timestamps):\n",
    "    start_time = max(timestamp - 2, 0)\n",
    "    end_time = min(timestamp + clip_duration, video.duration)\n",
    "    try:\n",
    "        subclip = video.subclip(start_time, end_time)\n",
    "        out_path = os.path.join(output_dir, f'{event_type}_{idx+1}.mp4')\n",
    "        subclip.write_videofile(out_path, codec='libx264', audio=False)\n",
    "        clips.append(subclip)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to cut clip at {timestamp:.2f}s: {e}\")\n",
    "\n",
    "# --- MERGE CLIPS ---\n",
    "if clips:\n",
    "    print(\"üéûÔ∏è Merging clips...\")\n",
    "    final_video = concatenate_videoclips(clips)\n",
    "    final_video.write_videofile(\"highlights.mp4\", codec='libx264', audio=False)\n",
    "    print(\"‚úÖ Highlight video generated: highlights.mp4\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No valid replay clips were extracted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10309d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Scanning video for replays...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6000/6000 [06:55<00:00, 14.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÇÔ∏è Extracting clips...\n",
      "‚ö†Ô∏è No valid replay clips were extracted.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from moviepy.editor import VideoFileClip, concatenate_videoclips\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "video_path = r'D:\\Ayush\\PROJECTS\\EE655\\Matches\\matchclip.mp4'\n",
    "output_dir = 'clips'\n",
    "frame_save_dir = 'detections'\n",
    "templates = {\n",
    "    'wicket': cv2.imread(r'D:\\Ayush\\PROJECTS\\EE655\\templates\\replay_wicket.png', 0),\n",
    "    'four': cv2.imread(r'D:\\Ayush\\PROJECTS\\EE655\\templates\\replay_four.png', 0),\n",
    "    'six': cv2.imread(r'D:\\Ayush\\PROJECTS\\EE655\\templates\\replay_six.png', 0)\n",
    "}\n",
    "trophy_template = cv2.imread(r'D:\\Ayush\\PROJECTS\\EE655\\templates\\trophy.png', 0)\n",
    "histogram_threshold = 0.7  # Lower value = more strict match\n",
    "trophy_threshold = 0.8\n",
    "clip_duration = 10\n",
    "frame_gap_seconds = 0.2  # Check every 0.2s\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(frame_save_dir, exist_ok=True)\n",
    "\n",
    "# --- HELPER: Histogram-based similarity ---\n",
    "def hist_similarity(img1, img2):\n",
    "    img1 = cv2.resize(img1, (200, 100))\n",
    "    img2 = cv2.resize(img2, (200, 100))\n",
    "    hist1 = cv2.calcHist([img1], [0], None, [256], [0, 256])\n",
    "    hist2 = cv2.calcHist([img2], [0], None, [256], [0, 256])\n",
    "    hist1 = cv2.normalize(hist1, hist1).flatten()\n",
    "    hist2 = cv2.normalize(hist2, hist2).flatten()\n",
    "    similarity = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)\n",
    "    return similarity\n",
    "\n",
    "# --- DETECTION ---\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    raise ValueError(\"‚ùå Could not open the video. Check the path.\")\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "if fps == 0:\n",
    "    print(\"‚ö†Ô∏è FPS is 0, defaulting to 25.\")\n",
    "    fps = 25\n",
    "\n",
    "frame_gap = int(fps * frame_gap_seconds)\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "replay_timestamps = []\n",
    "\n",
    "print(\"üîç Scanning video for replays...\")\n",
    "for i in tqdm(range(0, frame_count, frame_gap)):\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "    timestamp = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    if hist_similarity(frame_gray, trophy_template) > trophy_threshold:\n",
    "        continue\n",
    "\n",
    "    for event_type, template in templates.items():\n",
    "        sim = hist_similarity(frame_gray, template)\n",
    "        if sim > histogram_threshold:\n",
    "            replay_timestamps.append((timestamp, event_type))\n",
    "            frame_filename = f\"{frame_save_dir}/{event_type}_{int(timestamp)}.jpg\"\n",
    "            cv2.imwrite(frame_filename, frame)\n",
    "            print(f\"‚úÖ Detected {event_type.upper()} at {timestamp:.2f}s ‚Üí saved {frame_filename}\")\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# --- CLIP EXTRACTION ---\n",
    "clips = []\n",
    "video = VideoFileClip(video_path)\n",
    "print(\"‚úÇÔ∏è Extracting clips...\")\n",
    "\n",
    "for idx, (timestamp, event_type) in enumerate(replay_timestamps):\n",
    "    start_time = max(timestamp - 2, 0)\n",
    "    end_time = min(timestamp + clip_duration, video.duration)\n",
    "    try:\n",
    "        subclip = video.subclip(start_time, end_time)\n",
    "        out_path = os.path.join(output_dir, f'{event_type}_{idx+1}.mp4')\n",
    "        subclip.write_videofile(out_path, codec='libx264', audio=False)\n",
    "        clips.append(subclip)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to cut clip at {timestamp:.2f}s: {e}\")\n",
    "\n",
    "# --- MERGE CLIPS ---\n",
    "if clips:\n",
    "    print(\"üéûÔ∏è Merging clips...\")\n",
    "    final_video = concatenate_videoclips(clips)\n",
    "    final_video.write_videofile(\"highlights.mp4\", codec='libx264', audio=False)\n",
    "    print(\"‚úÖ Highlight video generated: highlights.mp4\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No valid replay clips were extracted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b58de556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Scanning video for replays...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting replays: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6000/6000 [07:21<00:00, 13.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÇÔ∏è Extracting clips...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \n",
      "                                                                        \n",
      "chunk:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 5559/12128 [2:11:58<00:11, 588.48it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video clips\\four_1.mp4.\n",
      "MoviePy - Writing audio in four_1TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                                                        \n",
      "                                                                        \n",
      "chunk:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 5559/12128 [2:12:18<00:11, 588.48it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video clips\\four_1.mp4\n",
      "\n",
      "‚ùå Failed to cut clip at 431.60s: must be real number, not NoneType\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \n",
      "                                                                        \n",
      "chunk:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 5559/12128 [2:12:18<00:11, 588.48it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video clips\\four_2.mp4.\n",
      "MoviePy - Writing audio in four_2TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                                                        \n",
      "                                                                        \n",
      "Extracting clips: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:26<00:00, 13.11s/it]now=None]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video clips\\four_2.mp4\n",
      "\n",
      "‚ùå Failed to cut clip at 943.76s: must be real number, not NoneType\n",
      "‚ö†Ô∏è No valid replay clips were extracted.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from moviepy.editor import VideoFileClip, concatenate_videoclips\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==== Config ====\n",
    "video_path = r\"D:\\Ayush\\PROJECTS\\EE655\\Matches\\matchclip.mp4\"\n",
    "template_paths = {\n",
    "    \"wicket\": r\"D:\\Ayush\\PROJECTS\\EE655\\templates\\replay_wicket.png\",\n",
    "    \"four\": r\"D:\\Ayush\\PROJECTS\\EE655\\templates\\replay_four.png\",\n",
    "    \"six\": r\"D:\\Ayush\\PROJECTS\\EE655\\templates\\replay_six.png\"\n",
    "}\n",
    "trophy_path = r\"D:\\Ayush\\PROJECTS\\EE655\\templates\\trophy.png\"\n",
    "\n",
    "output_dir = \"clips\"\n",
    "detected_frames_dir = \"detected_frames\"\n",
    "highlight_output = \"highlights.mp4\"\n",
    "clip_duration = 8  # seconds\n",
    "hist_threshold = 0.5\n",
    "trophy_threshold = 0.7  # Skip if correlation with trophy image is high\n",
    "frame_gap = 5  # Check every 5th frame (reduce for shorter screen flashes)\n",
    "\n",
    "# ==== Setup Directories ====\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(detected_frames_dir, exist_ok=True)\n",
    "\n",
    "# ==== Load Templates ====\n",
    "def load_template(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    return cv2.resize(img, (200, 100))\n",
    "\n",
    "templates = {name: load_template(p) for name, p in template_paths.items()}\n",
    "trophy_template = load_template(trophy_path)\n",
    "\n",
    "# ==== Histogram Correlation ====\n",
    "def hist_similarity(img1, img2):\n",
    "    img1 = cv2.resize(img1, (200, 100))\n",
    "    img2 = cv2.resize(img2, (200, 100))\n",
    "    hist1 = cv2.calcHist([img1], [0], None, [256], [0, 256])\n",
    "    hist2 = cv2.calcHist([img2], [0], None, [256], [0, 256])\n",
    "    cv2.normalize(hist1, hist1)\n",
    "    cv2.normalize(hist2, hist2)\n",
    "    return cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)\n",
    "\n",
    "# ==== Replay Detection ====\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "replay_timestamps = []\n",
    "\n",
    "print(\"üîç Scanning video for replays...\")\n",
    "for i in tqdm(range(0, frame_count, frame_gap), desc=\"Detecting replays\"):\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    timestamp = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0\n",
    "\n",
    "    # Skip if trophy template matched\n",
    "    if hist_similarity(gray, trophy_template) > trophy_threshold:\n",
    "        continue\n",
    "\n",
    "    for event_type, template in templates.items():\n",
    "        score = hist_similarity(gray, template)\n",
    "        if score > hist_threshold:\n",
    "            if not replay_timestamps or abs(timestamp - replay_timestamps[-1][1]) > clip_duration:\n",
    "                replay_timestamps.append((event_type, timestamp))\n",
    "                frame_path = os.path.join(detected_frames_dir, f\"{event_type}_{int(timestamp)}s.jpg\")\n",
    "                cv2.imwrite(frame_path, frame)\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# ==== Clip Extraction with Loading Bar ====\n",
    "print(\"\\n‚úÇÔ∏è Extracting clips...\")\n",
    "video_clip = VideoFileClip(video_path)\n",
    "clips = []\n",
    "\n",
    "for idx, (event_type, ts) in enumerate(tqdm(replay_timestamps, desc=\"Extracting clips\")):\n",
    "    try:\n",
    "        start = max(0, ts - 2)\n",
    "        end = start + clip_duration\n",
    "        subclip = video_clip.subclip(start, end)\n",
    "        clip_path = os.path.join(output_dir, f\"{event_type}_{idx+1}.mp4\")\n",
    "        subclip.write_videofile(clip_path, codec=\"libx264\", audio=False, verbose=False, logger=None)\n",
    "        clips.append(VideoFileClip(clip_path))\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to cut clip at {ts:.2f}s: {e}\")\n",
    "\n",
    "video_clip.close()\n",
    "\n",
    "# ==== Merge All Clips ====\n",
    "if clips:\n",
    "    final = concatenate_videoclips(clips)\n",
    "    final.write_videofile(highlight_output, codec=\"libx264\", audio=False)\n",
    "    print(f\"\\nüéâ Highlights saved to: {highlight_output}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No valid replay clips were extracted.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
